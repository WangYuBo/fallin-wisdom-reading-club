上次聊了AI的理论基础，哥德尔、图灵、冯诺依曼、维纳等大神挨个登场，铺平了实现AI理论之路。这一次，主要涉及到另一些AI重要和关键理论。比如自指、层次缠结。

先说一本大名鼎鼎AI科普书，《Godel.Escher.Bach:an Eternal Golden Braid》,简称GEB。作者侯世达，读了物理学博士，他父亲是诺贝尔物理学奖得主。但侯世达读完博士，兴趣却转向了意识与人工智能。作者在书中介绍了哥德尔定理，埃舍尔版画和巴赫音乐，他们会有一个共同的特征－层次缠结，作者称之为“一条永恒的金带”。

看起来很抽象，比较难理解，先说层次。比如楼梯，一层一层的，如果你愿意，我们就能从一楼爬到二十楼。再比如我们在手机上看高德地图，可以缩放，不同比例显示的地图范围不一样。又或者，“我的爸爸曾经听过他的爸爸说：‘我的爸爸曾经听过他的爸爸说：‘’.....’”诸如此类，都是有不同层次。层次缠结是什么呢？比如乌比斯环，你沿这一面走，走着走着就又走回了原点。曾经很火爆的手机游戏《纪念碑谷》，就是这个玩法。还有《盗梦空间》，主角穿越不同层次的梦境，很容易迷失其中。

自指就是层次缠结的一种，比如埃舍尔经典版画《僧侣》，这群可怜的僧侣围绕一层楼走，从这头走到那头，你顺着他们的路线看了一圈，竟然又回到了原点。再比如：
>　村里的理发师有条很奇特的规矩：他不给那些给自己理发的人理发。

这时候，我们从这个自指里看到了悖论。什么悖论呢？按照理发师的规矩，给自己理发的人，理发师是不会给他理发的；不给自己理发的人，理发师才给他理发。理发师是属于给自己理发的人么？如果要是，按照理发师的规则，理发师不应该给自己理发。如果不是，理发师是属于那些不给自己理发的人，理发师应该给自己理发。理发师好忧愁，到底是该给自己理发呢还是不该呢？

恭喜你，也发现了这个悖论。当初大数学家希尔伯特提出要构建完美的数学公理系统，既能用一个数学公理推导出另一个数学公理，这叫一致性，又能用这个系统证明自身，叫完备性。可惜，哥德尔就发现了类似悖论：一致性与完备性不可兼得啊～理发师悖论就是哥德尔定理的通俗版本。真哥德尔定理经过严密推理，数学系统自身指出了数学系统一致性与完备性不可兼得。

对人工智能的一个重要共识是，人工智能自我更新、有自我意识，算是真正意义上的人工智能。而哥德尔定理告诉我们，建立在数学与计算机系统之上的人工智能，依旧需要符合哥德尔定理，这就意味着，人工智能本身就是一个悖论，是一个永远自相矛盾的概念。

是不是只有这种没有建设意义的悖论呢？答案是否定的。我们知道，不是所有层次缠结都是自指，层次缠结是比自指更大的概念。还要一些自指可能包含创造和构建。比如二十世纪五六十年代，智利科学家温贝托马图拉纳(Humberto Maturana)和弗朗西斯科瓦瑞拉(Franciso Varela)就提出过一个“自创生(Autopoiesis)”理论。这个理论说，一个细胞可以看做一个化学反应物构成的生产网络，而且这个网络是一个闭环，就是这个网络中的任何物品都是网络中其他反应物生成的。还是用埃舍尔的画表示比较直观，看他的画作《画手》。相信大家都见过，左手画了右手，同时右手画了左手。这种网络有优良特性，能自我维持和自我修复。如果我们删除网络中一些节点，不至于太严重，它们还会被再生产出来，让系统继续维持正常运转。比如你家小朋友不小心磕破了手，过了几天它又自动愈合了。

这种生命的自复制，似乎是与生俱来，毫无难度的。对于一段数据，似乎也很容易，你在电脑上点“复制”，然后“粘贴”，复制似乎就完成了。但这算不上自复制，这个过程本质上是用你指挥电脑，用程序复制了一个数据，并不是没有你的参与，程序自己复制了自己。我们看这个句子：
> 把“把中的第一个字访道左引号前面，其余的字放到右引号后面，并保持引号及其中字数不变”中的第一个字放到左引号前面，其余的字放到右引号后面，并保持引号及其中字数不变。

你仔细的按照这个句子的要求做，你会发现，这句话的意思，已然清晰表达出了你正在做的事。这实际上是一种新的自指方法，被称为“蒯恩法”，纪念美国著名逻辑学家蒯恩。原始句子所指的对象本质上不是它自己，而是通过解读操作顺序而得的新句子。而这个新句子正好和原句子一样。通俗的说，如果你要自我复制，那么你需要复制身体部分自我信息，根据这些信息构造出一个新整体。比如生物学意义上，DNA编码，编码构造整体的过程就是蛋白质合成，然后蛋白质再生成DNA，这样就完成了生命自复制过程。

冯诺依曼在其生命最后时光都花在了研究生自复制。他观察到，当系统复杂度超过一定级别，就可以实现复杂性不断升级进化，而熵增定律在此开始失效，冯诺依曼认为这个贝叶斯概率中的一个漏洞。为什么是个漏洞呢？因为随机碰撞而成的随机网络，成功概率太小，但只要有一个进入蒯恩自指，那么，小概率事件就变成了大概率事件。社会学中有马太效应，强者愈强，弱者愈弱，异曲同工啊。

实现AI的关键理论，自指与层次缠结。那理论上有没有可能实现一个人工智能机器人，能够有自我意识，像人一样反省呢？
先说意识，人的意识就像一面镜子，虽然不像工业模子那么精准，能够反映任何事物，包括意识自身。比如你现在可以深呼吸一下，察觉下脑袋里有什么想法。自指就是自我意识最重要的属性。自我意识并不是你的身体或者大脑，也不是我们观察到的外边桌子椅子，而是这个观察、意识本身。你的记忆不是你，你的感受不是你，而那个真你，是你体察到到这些东西的能力。意识的自指特性，让我们体察到的世界，就像一个万花筒。

人类智能的最大特点，就是有这种自我觉知与自我反省的意识了。计算机现在还没有，有可能有呢？计算理论先驱很早就已经指出了这种具有自我觉知能力的程序，是有可能存在的。克林尼递归定理这样说：
> 对于任意程序F,总存在一段程序代码c,使得我们执行代码c的结果完全等价于把源代码c作为数据输入给程序F执行的结果。

看起来很平常吧？但它的重要在于，这段定理保证了一段程序可以计算出关于这段程序自身的各种属性，而这是实现程序自指甚至自我觉知不可或缺的一步。这个定理，让程序能够自我复制，并用自我复制的程序再进行自我复制，甚至不断升级，计算机病毒就是这样的程序。

而反省程序是什么样的呢？我也没理解，希望已经理解了的小伙伴不吝赐教。

